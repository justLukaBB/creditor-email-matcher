---
phase: 06-matching-engine-reconstruction
plan: 04
type: execute
wave: 3
depends_on: ["06-03"]
files_modified:
  - app/services/matching_engine_v2.py
autonomous: true

must_haves:
  truths:
    - "Matching engine filters candidates by 30-day creditor_inquiries window"
    - "No auto-match without recent creditor_inquiries record"
    - "Ambiguous matches (gap < threshold) route to manual review with top-3 candidates"
    - "All match results include explainability JSONB"
  artifacts:
    - path: "app/services/matching_engine_v2.py"
      provides: "MatchingEngineV2 class with creditor_inquiries integration"
      exports: ["MatchingEngineV2", "MatchCandidate"]
      min_lines: 200
  key_links:
    - from: "app/services/matching_engine_v2.py"
      to: "app/models/creditor_inquiry.py"
      via: "SQLAlchemy query with 30-day filter"
      pattern: "db.query\\(CreditorInquiry\\).*sent_at"
    - from: "app/services/matching_engine_v2.py"
      to: "app/services/matching/strategies.py"
      via: "strategy.evaluate()"
      pattern: "strategy.evaluate\\("
    - from: "app/services/matching_engine_v2.py"
      to: "app/services/matching/explainability.py"
      via: "ExplainabilityBuilder.build()"
      pattern: "ExplainabilityBuilder.build\\("
---

<objective>
Implement MatchingEngineV2 - the core matching engine with creditor_inquiries integration, ambiguity detection, and explainability.

Purpose: This is the heart of Phase 6 - reconstructing the bypassed v1 matching engine with CONTEXT.MD requirements.
Output: Complete MatchingEngineV2 class ready for pipeline integration.
</objective>

<execution_context>
@/Users/luka.s/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luka.s/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/06-matching-engine-reconstruction/06-CONTEXT.md
@.planning/phases/06-matching-engine-reconstruction/06-RESEARCH.md

# Existing v1 engine for reference (patterns to preserve)
@app/services/matching_engine.py

# Prior plan artifacts
# 06-01: Models (MatchingThreshold, CreditorInquiry, MatchResult)
# 06-02: Signal scorers, ExplainabilityBuilder
# 06-03: ThresholdManager, Strategies
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create MatchingEngineV2 with creditor_inquiries filtering</name>
  <files>app/services/matching_engine_v2.py</files>
  <action>
Create `app/services/matching_engine_v2.py` with MatchingEngineV2 class:

```python
"""
Matching Engine V2 (Phase 6: Matching Engine Reconstruction)

Reconstructed matching engine with:
- creditor_inquiries table integration (30-day filter)
- Fuzzy matching via RapidFuzz with OCR error handling
- Configurable thresholds per creditor category
- Explainability JSONB for debugging and threshold tuning
- Ambiguity detection with gap threshold

CONTEXT.MD DECISIONS (LOCKED):
- Both reference AND name signals required for match
- No auto-match without recent creditor_inquiries record
- Gap threshold for ambiguity routing to manual review
"""

from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from sqlalchemy.orm import Session
from sqlalchemy import and_
import structlog

from app.models import CreditorInquiry, MatchResult, IncomingEmail
from app.services.matching import (
    ThresholdManager,
    CombinedStrategy,
    ExplainabilityBuilder,
    StrategyResult,
)
from app.config import settings

logger = structlog.get_logger(__name__)

# Default lookback window (CONTEXT.MD: 30 days)
DEFAULT_LOOKBACK_DAYS = 30


@dataclass
class MatchCandidate:
    """
    Represents a single match candidate with scores and explainability.
    """
    inquiry: CreditorInquiry
    total_score: float
    component_scores: Dict[str, float]
    signal_details: Dict[str, Dict]
    strategy_used: str
    scoring_details: Dict[str, Any] = field(default_factory=dict)  # JSONB-ready

    @property
    def confidence_level(self) -> str:
        """Categorize match confidence for display."""
        if self.total_score >= 0.85:
            return "high"
        elif self.total_score >= 0.70:
            return "medium"
        else:
            return "low"


@dataclass
class MatchingResult:
    """
    Result of the matching process.
    """
    status: str  # auto_matched, ambiguous, below_threshold, no_candidates, no_recent_inquiry
    match: Optional[MatchCandidate] = None  # Selected match (if auto_matched)
    candidates: List[MatchCandidate] = field(default_factory=list)  # Top-k candidates
    gap: Optional[float] = None  # Score gap between #1 and #2
    gap_threshold: float = 0.15
    needs_review: bool = False
    review_reason: Optional[str] = None


class MatchingEngineV2:
    """
    Matching engine with creditor_inquiries integration and explainability.

    Usage:
        engine = MatchingEngineV2(db)
        result = engine.find_match(
            email_id=123,
            extracted_data={"client_name": "Max Mustermann", "reference_numbers": ["AZ-123"]},
            from_email="info@sparkasse.de",
            received_at=datetime.now()
        )

        if result.status == "auto_matched":
            # Process matched inquiry
            matched_inquiry = result.match.inquiry
        elif result.status == "ambiguous":
            # Route to manual review with candidates
            for candidate in result.candidates:
                print(f"{candidate.inquiry.client_name}: {candidate.total_score}")
    """

    def __init__(
        self,
        db: Session,
        strategy: Optional["MatchingStrategy"] = None,
        lookback_days: int = DEFAULT_LOOKBACK_DAYS
    ):
        """
        Initialize matching engine.

        Args:
            db: SQLAlchemy session
            strategy: Matching strategy (default: CombinedStrategy)
            lookback_days: Days to look back for creditor_inquiries (default: 30)
        """
        self.db = db
        self.strategy = strategy or CombinedStrategy()
        self.lookback_days = lookback_days
        self.threshold_manager = ThresholdManager(db)

        logger.info("matching_engine_v2_initialized",
                   strategy=type(self.strategy).__name__,
                   lookback_days=self.lookback_days)

    def find_match(
        self,
        email_id: int,
        extracted_data: Dict[str, Any],
        from_email: str,
        received_at: datetime,
        creditor_category: str = "default"
    ) -> MatchingResult:
        """
        Find matching inquiry for incoming email.

        CONTEXT.MD Implementation:
        1. Filter candidates by creditor_inquiries 30-day window
        2. Score each candidate using strategy (both signals required)
        3. Apply gap threshold for ambiguity detection
        4. Build explainability JSONB for all candidates

        Args:
            email_id: IncomingEmail.id for logging
            extracted_data: Dict with client_name, reference_numbers, etc.
            from_email: Sender email address
            received_at: When email was received
            creditor_category: For category-specific thresholds

        Returns:
            MatchingResult with status, match, candidates, gap
        """
        log = logger.bind(
            email_id=email_id,
            from_email=from_email,
            creditor_category=creditor_category
        )

        # Step 1: Get candidates from creditor_inquiries (30-day filter)
        candidates = self._get_candidate_inquiries(from_email, received_at)

        if not candidates:
            log.warning("no_candidates_in_window",
                       lookback_days=self.lookback_days)
            return MatchingResult(
                status="no_recent_inquiry",
                needs_review=True,
                review_reason="No inquiries sent in last 30 days"
            )

        log.info("candidates_found", count=len(candidates))

        # Step 2: Get thresholds and weights
        min_threshold = self.threshold_manager.get_min_match(creditor_category)
        gap_threshold = self.threshold_manager.get_gap_threshold(creditor_category)
        weights = self.threshold_manager.get_weights(creditor_category)

        log.debug("thresholds_loaded",
                 min_threshold=min_threshold,
                 gap_threshold=gap_threshold,
                 weights=weights)

        # Step 3: Score each candidate
        match_candidates: List[MatchCandidate] = []
        for inquiry in candidates:
            strategy_result = self.strategy.evaluate(inquiry, extracted_data, weights)

            # Build explainability JSONB
            scoring_details = ExplainabilityBuilder.build(
                inquiry=inquiry,
                extracted_data=extracted_data,
                component_scores=strategy_result.component_scores,
                signal_details=strategy_result.signal_details,
                final_score=strategy_result.score,
                match_status="pending",  # Updated after gap analysis
                gap=None,
                gap_threshold=gap_threshold,
                weights=weights
            )

            match_candidate = MatchCandidate(
                inquiry=inquiry,
                total_score=strategy_result.score,
                component_scores=strategy_result.component_scores,
                signal_details=strategy_result.signal_details,
                strategy_used=strategy_result.strategy_used,
                scoring_details=scoring_details
            )
            match_candidates.append(match_candidate)

        # Step 4: Sort by score (descending)
        match_candidates.sort(key=lambda x: x.total_score, reverse=True)

        # Log top candidates
        for i, mc in enumerate(match_candidates[:3], 1):
            log.info("match_candidate",
                    rank=i,
                    inquiry_id=mc.inquiry.id,
                    client_name=mc.inquiry.client_name,
                    score=round(mc.total_score, 4),
                    confidence=mc.confidence_level)

        # Step 5: Apply matching decision logic
        return self._decide_match(
            candidates=match_candidates,
            min_threshold=min_threshold,
            gap_threshold=gap_threshold,
            log=log
        )

    def _get_candidate_inquiries(
        self,
        from_email: str,
        received_at: datetime
    ) -> List[CreditorInquiry]:
        """
        Get candidate inquiries from creditor_inquiries table.

        CONTEXT.MD: Only consider pairs where we sent an inquiry in the last 30 days.
        This is the key optimization that narrows the search space.
        """
        lookback_date = received_at - timedelta(days=self.lookback_days)

        # Query inquiries within window
        candidates = self.db.query(CreditorInquiry).filter(
            and_(
                CreditorInquiry.sent_at >= lookback_date,
                CreditorInquiry.sent_at <= received_at,
            )
        ).order_by(
            CreditorInquiry.sent_at.desc()
        ).all()

        return candidates

    def _decide_match(
        self,
        candidates: List[MatchCandidate],
        min_threshold: float,
        gap_threshold: float,
        log: Any
    ) -> MatchingResult:
        """
        Apply matching decision logic with gap threshold.

        CONTEXT.MD Decisions:
        - Top match wins if "clearly ahead" of second place (gap >= threshold)
        - When gap threshold not met, route to manual review with top 3
        - Below-threshold candidates not shown to avoid information overload
        """
        if not candidates:
            return MatchingResult(
                status="no_candidates",
                needs_review=True,
                review_reason="No candidates to evaluate"
            )

        top = candidates[0]

        # Check minimum threshold first
        if top.total_score < min_threshold:
            log.info("below_threshold",
                    top_score=top.total_score,
                    min_threshold=min_threshold)

            # Update scoring_details with final status
            top.scoring_details["match_status"] = "below_threshold"

            return MatchingResult(
                status="below_threshold",
                candidates=candidates[:3],  # Top 3 for review
                needs_review=True,
                review_reason=f"Top score {top.total_score:.2f} below threshold {min_threshold}"
            )

        # Single candidate above threshold -> auto-match
        if len(candidates) == 1:
            top.scoring_details["match_status"] = "auto_matched"
            top.scoring_details["gap"] = 1.0

            log.info("auto_matched_single",
                    inquiry_id=top.inquiry.id,
                    score=top.total_score)

            return MatchingResult(
                status="auto_matched",
                match=top,
                candidates=[top],
                gap=1.0,
                gap_threshold=gap_threshold
            )

        # Multiple candidates: calculate gap
        second = candidates[1]
        gap = top.total_score - second.total_score

        # Update explainability with gap
        top.scoring_details["gap"] = round(gap, 4)

        if gap >= gap_threshold:
            # Clear winner -> auto-match
            top.scoring_details["match_status"] = "auto_matched"

            log.info("auto_matched_gap",
                    inquiry_id=top.inquiry.id,
                    score=top.total_score,
                    gap=gap,
                    gap_threshold=gap_threshold)

            return MatchingResult(
                status="auto_matched",
                match=top,
                candidates=candidates[:3],
                gap=gap,
                gap_threshold=gap_threshold
            )
        else:
            # Ambiguous -> manual review
            top.scoring_details["match_status"] = "ambiguous"

            log.warning("ambiguous_match",
                       top_score=top.total_score,
                       second_score=second.total_score,
                       gap=gap,
                       gap_threshold=gap_threshold)

            return MatchingResult(
                status="ambiguous",
                candidates=candidates[:3],  # Top 3 for reviewer
                gap=gap,
                gap_threshold=gap_threshold,
                needs_review=True,
                review_reason=f"Gap {gap:.2f} below threshold {gap_threshold}; top candidates too close"
            )

    def save_match_results(
        self,
        email_id: int,
        result: MatchingResult
    ) -> List[MatchResult]:
        """
        Persist match results to database.

        Saves all candidates with their scoring_details JSONB for explainability.
        """
        match_results = []

        for rank, candidate in enumerate(result.candidates, 1):
            mr = MatchResult(
                incoming_email_id=email_id,
                creditor_inquiry_id=candidate.inquiry.id,
                total_score=candidate.total_score,
                confidence_level=candidate.confidence_level,
                client_name_score=candidate.component_scores.get("client_name"),
                reference_number_score=candidate.component_scores.get("reference"),
                scoring_details=candidate.scoring_details,
                rank=rank,
                selected_as_match=(result.status == "auto_matched" and rank == 1),
                selection_method=result.status
            )
            self.db.add(mr)
            match_results.append(mr)

        self.db.flush()  # Get IDs without committing

        logger.info("match_results_saved",
                   email_id=email_id,
                   count=len(match_results),
                   status=result.status)

        return match_results


__all__ = ["MatchingEngineV2", "MatchCandidate", "MatchingResult"]
```
  </action>
  <verify>python -c "from app.services.matching_engine_v2 import MatchingEngineV2, MatchCandidate, MatchingResult; print('OK')"</verify>
  <done>MatchingEngineV2 class imports with find_match and save_match_results methods</done>
</task>

<task type="auto">
  <name>Task 2: Add tests for matching engine core functionality</name>
  <files>tests/test_matching_engine_v2.py</files>
  <action>
Create `tests/test_matching_engine_v2.py` with unit tests:

```python
"""
Tests for MatchingEngineV2 (Phase 6)

Tests cover:
- creditor_inquiries 30-day filter
- Both signals required (CONTEXT.MD)
- Gap threshold ambiguity detection
- Explainability JSONB format
"""

import pytest
from datetime import datetime, timedelta
from unittest.mock import Mock, patch, MagicMock
from decimal import Decimal

from app.services.matching_engine_v2 import MatchingEngineV2, MatchCandidate, MatchingResult
from app.services.matching import ThresholdManager


@pytest.fixture
def mock_db():
    """Mock database session."""
    return Mock()


@pytest.fixture
def mock_inquiry():
    """Create mock CreditorInquiry."""
    inquiry = Mock()
    inquiry.id = 1
    inquiry.client_name = "Max Mustermann"
    inquiry.client_name_normalized = "max mustermann"
    inquiry.creditor_email = "info@sparkasse.de"
    inquiry.reference_number = "AZ-12345"
    inquiry.sent_at = datetime.now() - timedelta(days=5)
    return inquiry


class TestMatchingEngineV2:
    """Tests for MatchingEngineV2 core functionality."""

    def test_no_candidates_returns_no_recent_inquiry(self, mock_db):
        """Test that empty candidate list returns no_recent_inquiry status."""
        mock_db.query.return_value.filter.return_value.order_by.return_value.all.return_value = []

        engine = MatchingEngineV2(mock_db)
        result = engine.find_match(
            email_id=1,
            extracted_data={"client_name": "Test"},
            from_email="test@test.de",
            received_at=datetime.now()
        )

        assert result.status == "no_recent_inquiry"
        assert result.needs_review is True

    def test_both_signals_required(self, mock_db, mock_inquiry):
        """CONTEXT.MD: Both name AND reference required for match."""
        mock_db.query.return_value.filter.return_value.order_by.return_value.all.return_value = [mock_inquiry]
        # Mock threshold queries to return defaults
        mock_db.query.return_value.filter.return_value.first.return_value = None

        engine = MatchingEngineV2(mock_db)

        # Test with missing reference - should have low score
        result = engine.find_match(
            email_id=1,
            extracted_data={"client_name": "Max Mustermann", "reference_numbers": []},
            from_email="test@test.de",
            received_at=datetime.now()
        )

        # With only name match, score should be penalized
        if result.candidates:
            # Either below_threshold or very low score
            assert result.candidates[0].total_score < 0.5 or result.status == "below_threshold"

    def test_gap_threshold_auto_match(self, mock_db, mock_inquiry):
        """Test that clear gap results in auto_match."""
        # Create second inquiry with lower expected match
        second_inquiry = Mock()
        second_inquiry.id = 2
        second_inquiry.client_name = "Hans Schmidt"
        second_inquiry.client_name_normalized = "hans schmidt"
        second_inquiry.reference_number = "AZ-99999"
        second_inquiry.sent_at = datetime.now() - timedelta(days=10)

        mock_db.query.return_value.filter.return_value.order_by.return_value.all.return_value = [
            mock_inquiry, second_inquiry
        ]
        mock_db.query.return_value.filter.return_value.first.return_value = None

        engine = MatchingEngineV2(mock_db)
        result = engine.find_match(
            email_id=1,
            extracted_data={"client_name": "Max Mustermann", "reference_numbers": ["AZ-12345"]},
            from_email="info@sparkasse.de",
            received_at=datetime.now()
        )

        # With good match on first and poor on second, gap should exceed threshold
        if result.status == "auto_matched":
            assert result.match is not None
            assert result.match.inquiry.id == mock_inquiry.id
            assert result.gap >= 0.15  # Default gap_threshold

    def test_explainability_jsonb_format(self, mock_db, mock_inquiry):
        """Test that scoring_details has correct JSONB structure."""
        mock_db.query.return_value.filter.return_value.order_by.return_value.all.return_value = [mock_inquiry]
        mock_db.query.return_value.filter.return_value.first.return_value = None

        engine = MatchingEngineV2(mock_db)
        result = engine.find_match(
            email_id=1,
            extracted_data={"client_name": "Max Mustermann", "reference_numbers": ["AZ-12345"]},
            from_email="test@test.de",
            received_at=datetime.now()
        )

        if result.candidates:
            scoring_details = result.candidates[0].scoring_details
            # Check required fields
            assert "version" in scoring_details
            assert "signals" in scoring_details
            assert "client_name" in scoring_details["signals"]
            assert "reference_number" in scoring_details["signals"]
            assert "weights" in scoring_details
            assert "filters_applied" in scoring_details
            assert scoring_details["filters_applied"]["both_signals_required"] is True


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```
  </action>
  <verify>python -m pytest tests/test_matching_engine_v2.py -v --tb=short 2>/dev/null || echo "Tests created (run pytest after full setup)"</verify>
  <done>Test file exists with tests for no_candidates, both_signals_required, gap_threshold, explainability format</done>
</task>

</tasks>

<verification>
1. MatchingEngineV2 imports: `from app.services.matching_engine_v2 import MatchingEngineV2`
2. Engine has find_match() and save_match_results() methods
3. find_match() returns MatchingResult with status, match, candidates, gap
4. Candidates have scoring_details JSONB with version, signals, weights, filters_applied
5. Test file exists at tests/test_matching_engine_v2.py
</verification>

<success_criteria>
- MatchingEngineV2 filters by 30-day creditor_inquiries window
- Both signals required rule enforced (0 score if either missing)
- Gap threshold determines auto_matched vs ambiguous status
- All candidates have explainability JSONB in scoring_details
- save_match_results persists to MatchResult table with rank and selection_method
- Tests cover core matching scenarios
</success_criteria>

<output>
After completion, create `.planning/phases/06-matching-engine-reconstruction/06-04-SUMMARY.md`
</output>
