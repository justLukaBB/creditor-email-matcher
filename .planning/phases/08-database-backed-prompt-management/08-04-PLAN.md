---
phase: 08-database-backed-prompt-management
plan: 04
type: execute
wave: 4
depends_on: ["08-03"]
files_modified:
  - scripts/seed_prompts.py
  - app/services/prompt_rollup.py
  - app/scheduler.py
autonomous: true

must_haves:
  truths:
    - "Seed script migrates hardcoded prompts to database as v1"
    - "Daily rollup job aggregates raw metrics into prompt_performance_daily"
    - "All 4 prompt types seeded: classification.email_intent, extraction.email_body, extraction.pdf_scanned, extraction.image"
    - "Rollup job runs via APScheduler alongside existing reconciliation job"
  artifacts:
    - path: "scripts/seed_prompts.py"
      provides: "Initial prompt migration script"
      contains: "def seed_initial_prompts"
    - path: "app/services/prompt_rollup.py"
      provides: "Daily metrics aggregation service"
      contains: "def aggregate_daily_metrics"
    - path: "app/scheduler.py"
      provides: "APScheduler integration for rollup job"
      contains: "prompt_rollup"
  key_links:
    - from: "scripts/seed_prompts.py"
      to: "app/models/prompt_template.py"
      via: "SQLAlchemy insert"
      pattern: "PromptTemplate"
    - from: "app/services/prompt_rollup.py"
      to: "app/models/prompt_metrics.py"
      via: "Aggregation query"
      pattern: "PromptPerformanceMetrics.*PromptPerformanceDaily"
---

<objective>
Seed initial prompts from hardcoded strings and implement daily metrics rollup job. Seeds create v1 of all prompts (active) from existing code. Rollup job aggregates raw metrics into daily summaries.

Purpose: Complete the prompt management system with initial data and automated maintenance.
Output: System operational with seeded prompts and scheduled metrics aggregation.
</objective>

<execution_context>
@/Users/luka.s/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luka.s/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-database-backed-prompt-management/08-CONTEXT.md
@.planning/phases/08-database-backed-prompt-management/08-RESEARCH.md
@.planning/phases/08-database-backed-prompt-management/08-03-SUMMARY.md
@app/services/intent_classifier.py (source of hardcoded prompt)
@app/services/entity_extractor_claude.py (source of hardcoded prompts)
@app/services/extraction/pdf_extractor.py (source of EXTRACTION_PROMPT)
@app/services/extraction/image_extractor.py (source of IMAGE_EXTRACTION_PROMPT)
@app/scheduler.py (existing APScheduler integration from Phase 1)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create seed script for initial prompts</name>
  <files>scripts/seed_prompts.py</files>
  <action>
Create seed script that migrates hardcoded prompts to database as v1 (active):

```python
#!/usr/bin/env python
"""
Seed Initial Prompts

Migrates hardcoded prompts from codebase to database as version 1.
All seeded prompts start as is_active=True (ready for production).

Usage:
    python scripts/seed_prompts.py

Idempotent: skips prompts that already exist (checks task_type + name + version).
"""

from sqlalchemy import and_
from app.database import SessionLocal
from app.models.prompt_template import PromptTemplate

PROMPTS_TO_SEED = [
    {
        'task_type': 'classification',
        'name': 'email_intent',
        'version': 1,
        'system_prompt': None,
        'user_prompt_template': '''Klassifiziere die E-Mail-Intent in eine der folgenden Kategorien:

1. debt_statement - Gläubigerantwort mit Forderungsbetrag oder Schuldenstatus
2. payment_plan - Zahlungsplan-Vorschlag oder Bestätigung
3. rejection - Ablehnung oder Widerspruch der Forderung
4. inquiry - Frage die manuelle Antwort erfordert
5. auto_reply - Abwesenheitsnotiz oder automatische Antwort
6. spam - Marketing, unrelated content

E-Mail:
Betreff: {{ subject }}
Text: {{ truncated_body }}

Antworte nur mit JSON:
{"intent": "debt_statement|payment_plan|rejection|inquiry|auto_reply|spam", "confidence": 0.0-1.0}''',
        'is_active': True,
        'created_by': 'system_migration',
        'description': 'Migrated from hardcoded intent_classifier.py',
        'model_name': 'claude-haiku-4-20250514',
        'temperature': 0.0,
        'max_tokens': 100
    },
    # ... (extraction.email_body with system_prompt and user_prompt_template)
    # ... (extraction.pdf_scanned)
    # ... (extraction.image)
]

def seed_initial_prompts():
    """Seed database with initial prompts."""
    # Implementation per RESEARCH.md code example
```

Include all 4 prompts:
1. classification.email_intent - from intent_classifier.py
2. extraction.email_body - from entity_extractor_claude.py (both system and user prompts)
3. extraction.pdf_scanned - from pdf_extractor.py EXTRACTION_PROMPT
4. extraction.image - from image_extractor.py IMAGE_EXTRACTION_PROMPT

Convert hardcoded f-string variables to Jinja2 {{ variable }} syntax.

Script should be idempotent (check if version exists before inserting).
  </action>
  <verify>python scripts/seed_prompts.py --help || python -c "exec(open('scripts/seed_prompts.py').read())" 2>/dev/null; echo "Script exists"</verify>
  <done>Seed script creates v1 of all 4 prompts as active, idempotent, ready to run after migration</done>
</task>

<task type="auto">
  <name>Task 2: Create daily metrics rollup service</name>
  <files>app/services/prompt_rollup.py</files>
  <action>
Create rollup service per RESEARCH.md Pattern 3:

```python
"""
Prompt Metrics Daily Rollup Service

Aggregates raw prompt_performance_metrics into prompt_performance_daily.
USER DECISION: 30-day raw retention, then aggregate to daily summaries.

Run daily at 01:00 to aggregate previous day's metrics.
"""

from datetime import date, timedelta
from sqlalchemy import func, select, cast, Integer
from sqlalchemy.orm import Session
import structlog

from app.models.prompt_metrics import PromptPerformanceMetrics, PromptPerformanceDaily

logger = structlog.get_logger(__name__)

def aggregate_daily_metrics(target_date: date, db: Session) -> int:
    """
    Aggregate raw metrics for given date into daily summary.

    Args:
        target_date: Date to aggregate (typically yesterday)
        db: Database session

    Returns:
        Number of prompt versions aggregated
    """
    logger.info("daily_rollup_started", date=str(target_date))

    # Query aggregated metrics grouped by prompt_template_id
    stmt = select(
        PromptPerformanceMetrics.prompt_template_id,
        func.count().label('total_extractions'),
        func.sum(PromptPerformanceMetrics.input_tokens).label('total_input_tokens'),
        func.sum(PromptPerformanceMetrics.output_tokens).label('total_output_tokens'),
        func.sum(PromptPerformanceMetrics.api_cost_usd).label('total_api_cost_usd'),
        func.sum(cast(PromptPerformanceMetrics.extraction_success, Integer)).label('successful_extractions'),
        func.avg(PromptPerformanceMetrics.confidence_score).label('avg_confidence_score'),
        func.sum(cast(PromptPerformanceMetrics.manual_review_required, Integer)).label('manual_review_count'),
        func.avg(PromptPerformanceMetrics.execution_time_ms).label('avg_execution_time_ms'),
        # Note: p95 requires window function or percentile_cont
    ).where(
        func.date(PromptPerformanceMetrics.extracted_at) == target_date
    ).group_by(
        PromptPerformanceMetrics.prompt_template_id
    )

    results = db.execute(stmt).fetchall()

    aggregated_count = 0
    for row in results:
        # Upsert daily rollup
        existing = db.query(PromptPerformanceDaily).filter(
            and_(
                PromptPerformanceDaily.prompt_template_id == row.prompt_template_id,
                PromptPerformanceDaily.date == target_date
            )
        ).first()

        if existing:
            # Update existing record
            existing.total_extractions = row.total_extractions
            # ... update all fields
        else:
            # Create new record
            rollup = PromptPerformanceDaily(
                prompt_template_id=row.prompt_template_id,
                date=target_date,
                total_extractions=row.total_extractions,
                # ... all fields from query
            )
            db.add(rollup)

        aggregated_count += 1

    db.commit()

    logger.info(
        "daily_rollup_completed",
        date=str(target_date),
        prompt_versions_aggregated=aggregated_count
    )

    return aggregated_count


def cleanup_old_raw_metrics(db: Session, retention_days: int = 30) -> int:
    """
    Delete raw metrics older than retention period.

    USER DECISION: 30-day raw retention.

    Args:
        db: Database session
        retention_days: Days to retain raw metrics (default 30)

    Returns:
        Number of records deleted
    """
    cutoff_date = date.today() - timedelta(days=retention_days)

    deleted = db.query(PromptPerformanceMetrics).filter(
        func.date(PromptPerformanceMetrics.extracted_at) < cutoff_date
    ).delete(synchronize_session=False)

    db.commit()

    logger.info(
        "raw_metrics_cleanup_completed",
        cutoff_date=str(cutoff_date),
        records_deleted=deleted
    )

    return deleted


def run_daily_rollup_job(db: Session):
    """
    Combined job: aggregate yesterday's metrics, cleanup old data.

    This is the scheduled job entry point.
    """
    yesterday = date.today() - timedelta(days=1)

    # Aggregate yesterday's metrics
    aggregate_daily_metrics(yesterday, db)

    # Cleanup old raw metrics
    cleanup_old_raw_metrics(db, retention_days=30)
```
  </action>
  <verify>python -c "from app.services.prompt_rollup import aggregate_daily_metrics, cleanup_old_raw_metrics, run_daily_rollup_job; print('Rollup service imported')"</verify>
  <done>Daily rollup service aggregates metrics, cleans up old raw data, ready for scheduler</done>
</task>

<task type="auto">
  <name>Task 3: Add rollup job to APScheduler</name>
  <files>app/scheduler.py</files>
  <action>
Add prompt metrics rollup job to existing APScheduler setup:

1. Read current app/scheduler.py (has reconciliation job from Phase 1)

2. Add import:
```python
from app.services.prompt_rollup import run_daily_rollup_job
```

3. Add new scheduled job in start_scheduler():
```python
def start_scheduler():
    """Start background scheduler with all jobs."""
    from apscheduler.schedulers.background import BackgroundScheduler

    scheduler = BackgroundScheduler()

    # Existing reconciliation job (hourly)
    scheduler.add_job(
        run_reconciliation,
        'interval',
        hours=1,
        id='reconciliation',
        name='PostgreSQL-MongoDB Reconciliation'
    )

    # NEW: Prompt metrics rollup (daily at 01:00)
    scheduler.add_job(
        _run_prompt_rollup,
        'cron',
        hour=1,
        minute=0,
        id='prompt_metrics_rollup',
        name='Prompt Metrics Daily Rollup'
    )

    scheduler.start()
    logger.info("scheduler_started", jobs=['reconciliation', 'prompt_metrics_rollup'])

def _run_prompt_rollup():
    """Wrapper to run rollup job with database session."""
    from app.database import SessionLocal
    db = SessionLocal()
    try:
        run_daily_rollup_job(db)
    except Exception as e:
        logger.error("prompt_rollup_job_failed", error=str(e))
    finally:
        db.close()
```

4. Ensure scheduler.py exports start_scheduler function.

The job runs at 01:00 daily to aggregate previous day's metrics and cleanup old data.
  </action>
  <verify>python -c "from app.scheduler import start_scheduler; print('Scheduler with rollup job ready')"</verify>
  <done>APScheduler runs daily rollup job at 01:00 alongside hourly reconciliation</done>
</task>

</tasks>

<verification>
1. scripts/seed_prompts.py exists and contains all 4 prompts
2. Seed script is idempotent (checks for existing versions)
3. prompt_rollup.py aggregates metrics into daily summaries
4. cleanup_old_raw_metrics deletes data older than 30 days
5. scheduler.py includes prompt_metrics_rollup job running at 01:00
6. All imports work without errors
</verification>

<success_criteria>
- Seed script migrates all 4 hardcoded prompts to database as v1 (active)
- Jinja2 variables correctly converted from f-string format
- Daily rollup aggregates raw metrics into prompt_performance_daily
- Raw metrics older than 30 days cleaned up automatically
- APScheduler runs rollup job daily at 01:00
- System ready for production deployment
</success_criteria>

<output>
After completion, create `.planning/phases/08-database-backed-prompt-management/08-04-SUMMARY.md`
</output>
