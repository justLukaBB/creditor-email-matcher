---
phase: 09-production-hardening-monitoring
plan: 03
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - app/models/operational_metrics.py
  - app/models/__init__.py
  - app/services/monitoring/metrics.py
  - app/services/monitoring/__init__.py
  - app/services/metrics_rollup.py
  - app/scheduler.py
  - alembic/versions/xxx_add_operational_metrics.py
autonomous: true

must_haves:
  truths:
    - "Queue depth, processing duration, and error rates are recorded"
    - "Metrics stored in PostgreSQL with 30-day raw retention"
    - "Daily rollup aggregates raw metrics into permanent storage"
  artifacts:
    - path: "app/models/operational_metrics.py"
      provides: "Raw and daily rollup metrics models"
      contains: "OperationalMetrics"
    - path: "app/services/monitoring/metrics.py"
      provides: "Metrics collection service"
      contains: "MetricsCollector"
    - path: "app/services/metrics_rollup.py"
      provides: "Daily aggregation job"
      contains: "run_operational_metrics_rollup"
  key_links:
    - from: "app/scheduler.py"
      to: "app/services/metrics_rollup.py"
      via: "scheduled job"
      pattern: "run_operational_metrics_rollup"
    - from: "app/services/monitoring/metrics.py"
      to: "app/models/operational_metrics.py"
      via: "SQLAlchemy model"
      pattern: "OperationalMetrics"
---

<objective>
Implement operational metrics collection with PostgreSQL storage, following the established rollup pattern from prompt_performance_metrics.

Purpose: Operational metrics (queue depth, processing time, error rates, token usage, confidence distribution) provide visibility into pipeline health without requiring additional infrastructure.

Output: Metrics models, collection service, and daily rollup job integrated with existing scheduler.
</objective>

<execution_context>
@/Users/luka.s/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luka.s/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-production-hardening-monitoring/09-CONTEXT.md
@.planning/phases/09-production-hardening-monitoring/09-RESEARCH.md

# Existing patterns to follow
@app/models/prompt_metrics.py
@app/services/prompt_rollup.py
@app/scheduler.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create operational metrics models (raw + daily rollup)</name>
  <files>
    app/models/operational_metrics.py
    app/models/__init__.py
  </files>
  <action>
    1. Create app/models/operational_metrics.py following prompt_metrics.py pattern:

       a. OperationalMetrics(Base) - Raw metrics, 30-day retention:
          - id: Integer, primary key
          - metric_type: String(50), nullable=False, indexed
            - Values: "queue_depth", "processing_time_ms", "error_count", "token_usage", "confidence_score"
          - metric_value: Float, nullable=False
          - labels: JSON, nullable=True
            - For queue_depth: {"queue": "email_processing"}
            - For processing_time_ms: {"actor": "process_email", "stage": "extraction"}
            - For error_count: {"actor": "process_email", "error_type": "TimeoutError"}
            - For token_usage: {"model": "claude-sonnet", "operation": "extraction"}
            - For confidence_score: {"bucket": "high|medium|low"}
          - email_id: Integer, ForeignKey("incoming_emails.id"), nullable=True (for per-email metrics)
          - recorded_at: DateTime(timezone=True), server_default=func.now(), indexed

       b. OperationalMetricsDaily(Base) - Daily rollup, permanent retention:
          - id: Integer, primary key
          - metric_type: String(50), nullable=False
          - date: Date, nullable=False
          - Aggregates:
            - sample_count: Integer
            - sum_value: Float (for counts like errors)
            - avg_value: Float
            - min_value: Float
            - max_value: Float
            - p95_value: Float, nullable=True
          - labels_key: String(100), nullable=True (for label-specific rollups, e.g., "actor:process_email")
          - __table_args__: Unique index on (metric_type, date, labels_key)

    2. Update app/models/__init__.py:
       - Add imports for OperationalMetrics, OperationalMetricsDaily

    Docstrings should note:
    - OperationalMetrics: "Raw metrics. Retention: 30 days. Cleaned by daily rollup job."
    - OperationalMetricsDaily: "Aggregated metrics. Retention: permanent."
  </action>
  <verify>
    python -c "from app.models.operational_metrics import OperationalMetrics, OperationalMetricsDaily; print('Models defined')"
  </verify>
  <done>
    OperationalMetrics model for raw metrics with labels JSON column.
    OperationalMetricsDaily model for permanent daily aggregates.
    Both models follow prompt_metrics.py pattern.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Alembic migration for operational metrics tables</name>
  <files>
    alembic/versions/xxx_add_operational_metrics.py
  </files>
  <action>
    Create migration file (use current timestamp for version):

    ```python
    """Add operational metrics tables

    Revision ID: [generate with alembic]
    Revises: [previous migration]
    Create Date: 2026-02-06
    """
    from alembic import op
    import sqlalchemy as sa
    from sqlalchemy.dialects.postgresql import JSON

    # revision identifiers
    revision = 'xxxxxxxxxxxx'
    down_revision = '[find latest]'
    branch_labels = None
    depends_on = None

    def upgrade() -> None:
        # Raw operational metrics (30-day retention)
        op.create_table(
            'operational_metrics',
            sa.Column('id', sa.Integer(), nullable=False),
            sa.Column('metric_type', sa.String(50), nullable=False),
            sa.Column('metric_value', sa.Float(), nullable=False),
            sa.Column('labels', JSON(), nullable=True),
            sa.Column('email_id', sa.Integer(), nullable=True),
            sa.Column('recorded_at', sa.DateTime(timezone=True), server_default=sa.func.now(), nullable=False),
            sa.PrimaryKeyConstraint('id'),
            sa.ForeignKeyConstraint(['email_id'], ['incoming_emails.id'], ondelete='SET NULL')
        )
        op.create_index('idx_ops_metrics_type', 'operational_metrics', ['metric_type'])
        op.create_index('idx_ops_metrics_recorded', 'operational_metrics', ['recorded_at'])

        # Daily rollup (permanent retention)
        op.create_table(
            'operational_metrics_daily',
            sa.Column('id', sa.Integer(), nullable=False),
            sa.Column('metric_type', sa.String(50), nullable=False),
            sa.Column('date', sa.Date(), nullable=False),
            sa.Column('labels_key', sa.String(100), nullable=True),
            sa.Column('sample_count', sa.Integer(), nullable=False),
            sa.Column('sum_value', sa.Float(), nullable=False),
            sa.Column('avg_value', sa.Float(), nullable=False),
            sa.Column('min_value', sa.Float(), nullable=False),
            sa.Column('max_value', sa.Float(), nullable=False),
            sa.Column('p95_value', sa.Float(), nullable=True),
            sa.PrimaryKeyConstraint('id')
        )
        op.create_index('idx_ops_daily_unique', 'operational_metrics_daily',
                       ['metric_type', 'date', 'labels_key'], unique=True)

    def downgrade() -> None:
        op.drop_table('operational_metrics_daily')
        op.drop_table('operational_metrics')
    ```

    Run: `alembic revision --autogenerate -m "add_operational_metrics"` to get proper revision ID
    Then manually verify and adjust the generated migration.
  </action>
  <verify>
    alembic upgrade head && python -c "from app.models.operational_metrics import OperationalMetrics; from app.database import SessionLocal; db = SessionLocal(); print(f'Table exists: {db.execute(\"SELECT 1 FROM operational_metrics LIMIT 0\")}')" 2>/dev/null || echo "Migration file created - run alembic upgrade head to apply"
  </verify>
  <done>
    Alembic migration creates operational_metrics and operational_metrics_daily tables.
    Indexes on metric_type, recorded_at for efficient queries.
    Unique constraint on daily rollup prevents duplicate aggregation.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create MetricsCollector service and rollup job</name>
  <files>
    app/services/monitoring/metrics.py
    app/services/metrics_rollup.py
    app/services/monitoring/__init__.py
    app/scheduler.py
  </files>
  <action>
    1. Create app/services/monitoring/metrics.py:

       a. MetricsCollector class:
          - __init__(db: Session)
          - record_queue_depth(queue_name: str, depth: int)
          - record_processing_time(actor_name: str, stage: str, duration_ms: int, email_id: int = None)
          - record_error(actor_name: str, error_type: str, email_id: int = None)
          - record_token_usage(model: str, operation: str, tokens: int, email_id: int = None)
          - record_confidence(bucket: str, score: float, email_id: int = None)
            - bucket is "high", "medium", or "low" based on thresholds

          Each method creates OperationalMetrics record with appropriate labels.
          Do NOT commit - caller controls transaction (same pattern as DualDatabaseWriter).

       b. Helper function: get_metrics_collector(db: Session) -> MetricsCollector

    2. Create app/services/metrics_rollup.py (following prompt_rollup.py pattern):

       a. run_operational_metrics_rollup(db: Session):
          - Calculate rollup date (yesterday)
          - Query raw metrics for that date, grouped by (metric_type, labels_key)
          - For each group: calculate sum, avg, min, max, p95 (use SQLAlchemy func.percentile_cont if available, else approximate)
          - Upsert into OperationalMetricsDaily (update if exists, insert if new)
          - Delete raw metrics older than 30 days (USER DECISION: match prompt metrics retention)
          - Log summary: metrics rolled up, records cleaned

       b. Scheduler wrapper: run_scheduled_operational_rollup()
          - Similar pattern to run_prompt_rollup() in scheduler.py

    3. Update app/services/monitoring/__init__.py:
       - Export MetricsCollector, get_metrics_collector

    4. Update app/scheduler.py:
       - Import run_scheduled_operational_rollup from app.services.metrics_rollup
       - Add job to scheduler (daily at 01:30, 30 min after prompt rollup):
         ```python
         scheduler.add_job(
             run_scheduled_operational_rollup,
             trigger=CronTrigger(hour=1, minute=30),
             id="operational_metrics_rollup",
             name="Operational Metrics Daily Rollup",
             replace_existing=True
         )
         ```
  </action>
  <verify>
    python -c "from app.services.monitoring.metrics import MetricsCollector; from app.services.metrics_rollup import run_operational_metrics_rollup; print('Metrics service imports successfully')"
  </verify>
  <done>
    MetricsCollector provides methods for recording queue depth, processing time, errors, token usage, confidence.
    run_operational_metrics_rollup aggregates raw metrics and cleans old data.
    Rollup job scheduled for daily at 01:30 in scheduler.py.
  </done>
</task>

</tasks>

<verification>
1. Model test: `python -c "from app.models.operational_metrics import OperationalMetrics, OperationalMetricsDaily; print('Models import successfully')"`
2. Service test: `python -c "from app.services.monitoring.metrics import MetricsCollector; from app.database import SessionLocal; mc = MetricsCollector(SessionLocal()); print('MetricsCollector created')"`
3. Scheduler test: `python -c "from app.scheduler import start_scheduler; s = start_scheduler('testing'); print([j.id for j in s.get_jobs()])"`
</verification>

<success_criteria>
- OperationalMetrics and OperationalMetricsDaily models created with proper indexes
- Alembic migration creates both tables
- MetricsCollector provides record_* methods for all metric types (REQ-OPS-02)
- Rollup job aggregates metrics and cleans data older than 30 days
- Scheduler runs operational rollup daily at 01:30
</success_criteria>

<output>
After completion, create `.planning/phases/09-production-hardening-monitoring/09-03-SUMMARY.md`
</output>
