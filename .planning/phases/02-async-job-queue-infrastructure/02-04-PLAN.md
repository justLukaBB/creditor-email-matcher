---
phase: 02-async-job-queue-infrastructure
plan: 04
type: execute
wave: 2
depends_on: ["02-01", "02-02"]
files_modified:
  - app/routers/jobs.py
  - app/routers/__init__.py
  - app/services/failure_notifier.py
  - app/main.py
  - Procfile
autonomous: true

must_haves:
  truths:
    - "GET /api/v1/jobs returns list of jobs with status, timestamps, errors"
    - "GET /api/v1/jobs/{id} returns detailed job status"
    - "Failure notifier sends email on permanent job failure"
    - "Procfile starts both web and worker processes"
    - "main.py includes webhook and jobs routers"
  artifacts:
    - path: "app/routers/jobs.py"
      provides: "Job status REST API endpoints"
      exports: ["router"]
      contains: "GET"
    - path: "app/services/failure_notifier.py"
      provides: "Email notification on permanent failure"
      contains: "send_failure_notification"
    - path: "Procfile"
      provides: "Render process configuration"
      contains: "dramatiq"
    - path: "app/main.py"
      provides: "FastAPI app with all routers registered"
      contains: "include_router"
  key_links:
    - from: "app/main.py"
      to: "app/routers/webhook.py"
      via: "include_router registers webhook routes"
      pattern: "include_router.*webhook"
    - from: "app/main.py"
      to: "app/routers/jobs.py"
      via: "include_router registers job status routes"
      pattern: "include_router.*jobs"
    - from: "Procfile"
      to: "app/worker.py"
      via: "worker process command"
      pattern: "dramatiq app\\.worker"
    - from: "app/services/failure_notifier.py"
      to: "app/config.py"
      via: "Uses SMTP settings for email"
      pattern: "settings\\.smtp"
---

<objective>
Create job status API endpoints, failure notification service, Procfile for dual-process deployment, and wire all routers into main.py.

Purpose: Provides operational visibility (job status API), alerting (failure emails), deployment config (Procfile), and completes the integration by registering all routers in the FastAPI app.
Output: Working job status API, failure notification service, production-ready Procfile, and fully wired main.py.
</objective>

<execution_context>
@/Users/luka.s/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luka.s/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/02-async-job-queue-infrastructure/02-CONTEXT.md
@.planning/phases/02-async-job-queue-infrastructure/02-RESEARCH.md
@.planning/phases/02-async-job-queue-infrastructure/02-01-SUMMARY.md
@.planning/phases/02-async-job-queue-infrastructure/02-02-SUMMARY.md
@app/main.py
@app/routers/__init__.py
@app/config.py
@app/models/incoming_email.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Job status API and failure notification service</name>
  <files>app/routers/jobs.py, app/services/failure_notifier.py</files>
  <action>
**Part A: Create app/routers/jobs.py**

REST API endpoints for job status visibility (per CONTEXT.md: no auth, rely on Render internal networking):

1. `GET /api/v1/jobs` -- list recent jobs with optional filters:
   - Query params: `status: Optional[str]` (filter by processing_status), `limit: int = 50` (max 200)
   - Returns list of jobs: id, processing_status, from_email, subject (truncated to 100 chars), received_at, started_at, completed_at, processing_error
   - Order by received_at DESC (newest first)
   - Include summary stats in response: `{"total": N, "by_status": {"received": N, "queued": N, ...}, "jobs": [...]}`

2. `GET /api/v1/jobs/{job_id}` -- detailed status for single job:
   - Returns: id, processing_status, from_email, subject, received_at, started_at, completed_at, processing_time_seconds (calculated), processing_error, retry_count, extracted_data, match_status, match_confidence, attachment_urls, sync_status
   - 404 if not found

3. `POST /api/v1/jobs/{job_id}/retry` -- manually re-enqueue a failed job:
   - Only works on jobs with processing_status = "failed"
   - Resets processing_status to "queued", clears processing_error, increments retry_count
   - Enqueues via `process_email.send(email_id=job_id)`
   - Returns 200 with new status
   - Returns 400 if job is not in "failed" status

Use structlog for logging. Use Depends(get_db) for database session.

**Part B: Create app/services/failure_notifier.py**

Service to send email notifications when jobs permanently fail:

1. `FailureNotifier` class with:
   - `__init__(self)`: load SMTP settings from app.config.settings
   - `send_failure_notification(self, email_id: int, error: str, from_email: str, subject: str)`:
     - If smtp_host not configured, log warning and return (graceful degradation)
     - Build email with:
       - To: settings.admin_email (or fallback to hardcoded if not set -- log warning)
       - Subject: f"[ALERT] Email Processing Failed - ID {email_id}"
       - Body: plain text with email_id, from_email, subject, error message, timestamp, and link hint to /api/v1/jobs/{email_id}
     - Send via smtplib.SMTP with TLS
     - Catch and log any SMTP errors (do NOT raise -- notification failure should not cascade)

2. Module-level singleton: `failure_notifier = FailureNotifier()`

3. `notify_permanent_failure(email_id: int)` standalone function (called from actor's on_failure or exception handler):
   - Load email from database to get from_email and subject
   - Call failure_notifier.send_failure_notification(...)
   - Wrap in try/except to never raise (notification is best-effort)
  </action>
  <verify>
Run `python -c "from app.routers.jobs import router; print([r.path for r in router.routes])"` -- should show /api/v1/jobs routes.
Run `python -c "from app.services.failure_notifier import failure_notifier; print(type(failure_notifier))"` -- should print FailureNotifier.
  </verify>
  <done>
Job status API at /api/v1/jobs with list, detail, and manual retry endpoints. Failure notifier sends email alerts on permanent failures using existing SMTP config. Both handle missing configuration gracefully.
  </done>
</task>

<task type="auto">
  <name>Task 2: Procfile, main.py integration, and router wiring</name>
  <files>Procfile, app/main.py, app/routers/__init__.py</files>
  <action>
**Part A: Create Procfile**

Create `Procfile` at project root (not in _existing-code) with two process types:

```
web: uvicorn app.main:app --host 0.0.0.0 --port $PORT
worker: dramatiq app.worker --processes 2 --threads 1 --verbose
```

This runs both processes in same Render service per CONTEXT.md decision. The web process handles HTTP requests, the worker process runs Dramatiq actors.

**Part B: Update app/main.py**

1. **Uncomment and update router imports:**
   ```python
   from app.routers.webhook import router as webhook_router
   from app.routers.jobs import router as jobs_router
   ```

2. **Register routers after app creation:**
   ```python
   app.include_router(webhook_router)
   app.include_router(jobs_router)
   ```

3. **Remove the commented-out router lines** (`# from app.routers import webhook, inquiries`, `# app.include_router(webhook.router)`, etc.)

4. **Keep everything else unchanged**: APScheduler setup, health endpoint, reconciliation trigger, startup/shutdown events. Do NOT modify the scheduler logic.

5. **Update version** from "0.2.0" to "0.3.0" to reflect Phase 2 additions.

**Part C: Update app/routers/__init__.py**

Update to export both routers:
```python
from app.routers.webhook import router as webhook_router
from app.routers.jobs import router as jobs_router
```

IMPORTANT: Do NOT touch the APScheduler reconciliation code in main.py. Per CONTEXT.md: "Keep APScheduler for reconciliation as-is. Don't migrate to Dramatiq periodic tasks."
  </action>
  <verify>
Run `python -c "from app.main import app; print([r.path for r in app.routes])"` -- should include /api/v1/zendesk/webhook, /api/v1/jobs, /health, /.
Check Procfile exists: `cat Procfile` -- should show web and worker commands.
Verify version bump: `python -c "from app.main import app; print(app.version)"` -- should print 0.3.0.
  </verify>
  <done>
Procfile defines web (uvicorn) and worker (dramatiq) processes for Render deployment. main.py registers webhook and jobs routers. App version bumped to 0.3.0.
  </done>
</task>

</tasks>

<verification>
- Procfile has both web and worker process types
- main.py includes webhook_router and jobs_router
- GET /api/v1/jobs endpoint exists
- GET /api/v1/jobs/{id} endpoint exists
- POST /api/v1/jobs/{id}/retry endpoint exists
- FailureNotifier handles missing SMTP config gracefully
- APScheduler reconciliation code unchanged
</verification>

<success_criteria>
- Job status is visible via REST API without authentication (per CONTEXT.md)
- Failed jobs can be manually retried via API
- Email notification sent on permanent failure (when SMTP configured)
- Procfile ready for Render deployment with web + worker processes
- All routers wired into FastAPI app
</success_criteria>

<output>
After completion, create `.planning/phases/02-async-job-queue-infrastructure/02-04-SUMMARY.md`
</output>
