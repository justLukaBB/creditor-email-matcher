---
phase: 04-german-document-extraction
plan: 04
type: execute
wave: 2
depends_on: ["04-01", "04-02"]
files_modified:
  - app/services/extraction/email_body_extractor.py
  - app/services/extraction/docx_extractor.py
  - app/services/extraction/xlsx_extractor.py
  - app/services/extraction/__init__.py
autonomous: true

must_haves:
  truths:
    - "All text extractors apply Unicode NFKC normalization before extraction"
    - "Amount parsing uses babel-based parse_german_amount instead of manual replacement"
    - "Name fields use OCR correction via preprocessor"
    - "Email body extractor handles German format amounts correctly"
    - "DOCX and XLSX extractors normalize text before extraction"
  artifacts:
    - path: "app/services/extraction/email_body_extractor.py"
      provides: "Updated extractor with German preprocessing"
      contains: "GermanTextPreprocessor"
    - path: "app/services/extraction/docx_extractor.py"
      provides: "Updated extractor with German preprocessing"
      contains: "GermanTextPreprocessor"
    - path: "app/services/extraction/xlsx_extractor.py"
      provides: "Updated extractor with German preprocessing"
      contains: "GermanTextPreprocessor"
  key_links:
    - from: "app/services/extraction/email_body_extractor.py"
      to: "app/services/extraction/german_parser.py"
      via: "import parse_german_amount"
      pattern: "from.*german_parser.*import.*parse_german_amount"
    - from: "app/services/extraction/email_body_extractor.py"
      to: "app/services/extraction/german_preprocessor.py"
      via: "import GermanTextPreprocessor"
      pattern: "from.*german_preprocessor.*import.*GermanTextPreprocessor"
---

<objective>
Integrate German preprocessing and parsing into all text-based extractors.

Purpose: Wire the GermanTextPreprocessor and parse_german_amount into email body, DOCX, and XLSX extractors so all text extraction benefits from Unicode normalization, OCR correction, and locale-aware amount parsing.

Output: All text extractors use German preprocessing and babel-based amount parsing.
</objective>

<execution_context>
@/Users/luka.s/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luka.s/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-german-document-extraction/04-CONTEXT.md
@.planning/phases/04-german-document-extraction/04-RESEARCH.md
@.planning/phases/04-german-document-extraction/04-01-PLAN.md
@.planning/phases/04-german-document-extraction/04-02-PLAN.md
@app/services/extraction/email_body_extractor.py
@app/services/extraction/docx_extractor.py
@app/services/extraction/xlsx_extractor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate German preprocessing into EmailBodyExtractor</name>
  <files>
    app/services/extraction/email_body_extractor.py
  </files>
  <action>
Update `app/services/extraction/email_body_extractor.py` to use German preprocessing and parsing:

1. Add imports at top:
```python
from app.services.extraction.german_preprocessor import GermanTextPreprocessor
from app.services.extraction.german_parser import parse_german_amount
```

2. Add preprocessor to __init__:
```python
def __init__(self):
    self.preprocessor = GermanTextPreprocessor()
    # ... existing amount_patterns ...
```

3. Update extract() method to preprocess text first:
```python
def extract(self, email_text: str) -> SourceExtractionResult:
    # ... existing result initialization ...

    if not email_text or not email_text.strip():
        result.error = "empty_email_body"
        logger.warning("EmailBodyExtractor: empty email body")
        return result

    # NEW: Apply German preprocessing (Unicode normalization + OCR correction)
    preprocessed_text = self.preprocessor.preprocess(email_text)

    # Find all amounts in preprocessed text
    found_amounts = self._find_amounts(preprocessed_text)
    # ... rest of method unchanged ...
```

4. Update _find_amounts() to use parse_german_amount:
```python
def _find_amounts(self, text: str) -> List[Dict[str, Any]]:
    found_amounts = []

    for pattern in self.amount_patterns:
        for match in re.finditer(pattern, text):
            try:
                # Handle both patterns: "1.234,56 EUR" and "EUR 1.234,56"
                groups = match.groups()
                if groups[0] in ('EUR', '\u20ac'):
                    amount_str = groups[1]
                else:
                    amount_str = groups[0]

                # NEW: Use babel-based parser instead of manual replacement
                try:
                    amount_value = parse_german_amount(amount_str)
                except ValueError:
                    continue  # Skip unparseable amounts

                if amount_value > 0:
                    # Confidence: HIGH if German format detected (has comma decimal)
                    has_german_decimal = ',' in amount_str and amount_str.index(',') > amount_str.rfind('.')
                    found_amounts.append({
                        'value': amount_value,
                        'raw': match.group(0),
                        'confidence': 'HIGH' if has_german_decimal else 'MEDIUM'
                    })
            except (ValueError, IndexError):
                continue

    return found_amounts
```

5. Update _extract_names() to use preprocessor for name correction:
```python
def _extract_names(self, text: str, result: SourceExtractionResult) -> None:
    # ... existing pattern matching ...

    for pattern, entity_type in name_patterns:
        match = re.search(pattern, text)
        if match:
            name = match.group(1).strip()
            name = re.sub(r'[,.\s]+$', '', name)

            # NEW: Apply OCR correction to name fields only
            name = self.preprocessor.correct_name_field(name)

            if len(name) > 3:
                # ... rest unchanged ...
```
  </action>
  <verify>
python -c "from app.services.extraction.email_body_extractor import EmailBodyExtractor; e = EmailBodyExtractor(); r = e.extract('Gesamtforderung: 1.234,56 EUR'); print(r.gesamtforderung.value if r.gesamtforderung else 'None')"
  </verify>
  <done>
EmailBodyExtractor now uses GermanTextPreprocessor for Unicode normalization and OCR correction. Amount parsing uses babel-based parse_german_amount. Name extraction uses OCR correction.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate German preprocessing into DOCXExtractor</name>
  <files>
    app/services/extraction/docx_extractor.py
  </files>
  <action>
Update `app/services/extraction/docx_extractor.py` to use German preprocessing:

1. Add imports at top:
```python
from app.services.extraction.german_preprocessor import GermanTextPreprocessor
from app.services.extraction.german_parser import parse_german_amount
```

2. Add preprocessor to __init__:
```python
def __init__(self):
    self.preprocessor = GermanTextPreprocessor()
```

3. Update text extraction to preprocess:
After extracting text from paragraphs and tables, apply preprocessing:
```python
# After combining all text
combined_text = "\n".join(all_text)

# NEW: Apply German preprocessing
combined_text = self.preprocessor.preprocess(combined_text)
```

4. Update amount parsing to use parse_german_amount:
Replace any manual German number parsing (`.replace('.', '').replace(',', '.')`) with:
```python
try:
    amount_value = parse_german_amount(amount_str)
except ValueError:
    continue
```

5. Apply OCR correction to extracted names:
```python
if name:
    name = self.preprocessor.correct_name_field(name)
```

Note: If DOCXExtractor doesn't exist or has minimal logic, create it following the same pattern as EmailBodyExtractor but reading from python-docx Document object.
  </action>
  <verify>
python -c "from app.services.extraction.docx_extractor import DOCXExtractor; print('DOCXExtractor imported')"
  </verify>
  <done>
DOCXExtractor now uses GermanTextPreprocessor for text normalization. Amount parsing uses babel-based parser.
  </done>
</task>

<task type="auto">
  <name>Task 3: Integrate German preprocessing into XLSXExtractor</name>
  <files>
    app/services/extraction/xlsx_extractor.py
  </files>
  <action>
Update `app/services/extraction/xlsx_extractor.py` to use German preprocessing:

1. Add imports at top:
```python
from app.services.extraction.german_preprocessor import GermanTextPreprocessor
from app.services.extraction.german_parser import parse_german_amount
```

2. Add preprocessor to __init__:
```python
def __init__(self):
    self.preprocessor = GermanTextPreprocessor()
```

3. Update cell text extraction to preprocess:
When reading cell values, apply preprocessing:
```python
# When extracting text from cells
cell_text = str(cell.value) if cell.value else ""
cell_text = self.preprocessor.preprocess(cell_text)
```

4. Update amount parsing to use parse_german_amount:
Replace any manual German number parsing with:
```python
try:
    amount_value = parse_german_amount(amount_str)
except ValueError:
    continue
```

5. Apply OCR correction to extracted names (if XLSX has name columns):
```python
if name:
    name = self.preprocessor.correct_name_field(name)
```

Note: XLSX files often have clean numeric data, but text labels may still need normalization for consistent matching.
  </action>
  <verify>
python -c "from app.services.extraction.xlsx_extractor import XLSXExtractor; print('XLSXExtractor imported')"
  </verify>
  <done>
XLSXExtractor now uses GermanTextPreprocessor for text normalization. Amount parsing uses babel-based parser.
  </done>
</task>

<task type="auto">
  <name>Task 4: Update extraction package __init__.py exports</name>
  <files>
    app/services/extraction/__init__.py
  </files>
  <action>
Update `app/services/extraction/__init__.py` to export the new German processing modules:

Add to imports:
```python
from app.services.extraction.german_preprocessor import GermanTextPreprocessor
from app.services.extraction.german_validator import GermanValidator
from app.services.extraction.german_parser import parse_german_amount, extract_amount_from_text
```

Add to __all__ list:
```python
__all__ = [
    # ... existing exports ...
    "GermanTextPreprocessor",
    "GermanValidator",
    "parse_german_amount",
    "extract_amount_from_text",
]
```

This enables clean imports like:
```python
from app.services.extraction import GermanTextPreprocessor, parse_german_amount
```
  </action>
  <verify>
python -c "from app.services.extraction import GermanTextPreprocessor, GermanValidator, parse_german_amount; print('All German modules exported')"
  </verify>
  <done>
All German processing modules are exported from the extraction package __init__.py.
  </done>
</task>

</tasks>

<verification>
1. Run: `python -c "from app.services.extraction.email_body_extractor import EmailBodyExtractor; e = EmailBodyExtractor(); r = e.extract('Gesamtforderung: 1.234,56 EUR'); print(r.gesamtforderung)"`
2. Run: `python -c "from app.services.extraction import GermanTextPreprocessor, parse_german_amount"`
3. Run: `python -m pytest tests/test_german_preprocessor.py tests/test_german_parser.py -v` (verify existing tests still pass)
4. Verify all extractors can be imported without errors
</verification>

<success_criteria>
- EmailBodyExtractor uses GermanTextPreprocessor.preprocess() on input text
- EmailBodyExtractor uses parse_german_amount() instead of manual parsing
- EmailBodyExtractor uses correct_name_field() for extracted names
- DOCXExtractor applies German preprocessing to extracted text
- XLSXExtractor applies German preprocessing to cell text
- All German modules exported from extraction package __init__.py
- Existing tests continue to pass
</success_criteria>

<output>
After completion, create `.planning/phases/04-german-document-extraction/04-04-SUMMARY.md`
</output>
