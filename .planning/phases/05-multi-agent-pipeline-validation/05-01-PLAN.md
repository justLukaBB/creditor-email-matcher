---
phase: 05-multi-agent-pipeline-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/models/incoming_email.py
  - app/models/intent_classification.py
  - app/services/validation/__init__.py
  - app/services/validation/schema_validator.py
  - app/services/validation/confidence_checker.py
  - alembic/versions/XXXX_add_agent_checkpoints_column.py
autonomous: true

must_haves:
  truths:
    - "IncomingEmail has agent_checkpoints JSONB column for storing intermediate results"
    - "IntentResult model defines 6 intent types with confidence and method"
    - "SchemaValidator preserves partial results when fields fail validation"
    - "ConfidenceChecker flags items with confidence < 0.7 for review"
  artifacts:
    - path: "app/models/incoming_email.py"
      provides: "agent_checkpoints JSONB column"
      contains: "agent_checkpoints = Column"
    - path: "app/models/intent_classification.py"
      provides: "Intent enum and IntentResult model"
      exports: ["EmailIntent", "IntentResult"]
    - path: "app/services/validation/schema_validator.py"
      provides: "Pydantic validation with partial results"
      exports: ["validate_with_partial_results"]
    - path: "app/services/validation/confidence_checker.py"
      provides: "Confidence threshold checking"
      exports: ["check_confidence_threshold"]
  key_links:
    - from: "app/services/validation/schema_validator.py"
      to: "pydantic.ValidationError"
      via: "try/except with field extraction"
      pattern: "except ValidationError as e"
---

<objective>
Create foundation infrastructure for the multi-agent pipeline: checkpoint storage, intent classification models, and validation services.

Purpose: Enable all three agents to save intermediate results and enable validation layers between agents.
Output: Database migration, intent models, and validation utilities that agents will use.
</objective>

<execution_context>
@/Users/luka.s/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luka.s/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-multi-agent-pipeline-validation/05-CONTEXT.md
@.planning/phases/05-multi-agent-pipeline-validation/05-RESEARCH.md

@app/models/incoming_email.py
@app/models/extraction_result.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add checkpoint storage and intent models</name>
  <files>
    app/models/incoming_email.py
    app/models/intent_classification.py
    app/models/__init__.py
    alembic/versions/XXXX_add_agent_checkpoints_column.py
  </files>
  <action>
1. Update app/models/incoming_email.py:
   - Add `agent_checkpoints = Column(JSONB, nullable=True, default=dict)` column
   - Import JSONB from sqlalchemy.dialects.postgresql
   - Add docstring explaining checkpoint structure:
     ```
     # Structure:
     # {
     #   "agent_1_intent": {"intent": "...", "confidence": 0.85, "method": "...", "timestamp": "...", "validation_status": "..."},
     #   "agent_2_extraction": {"sources_processed": 3, "gesamtforderung": 1500.0, ...},
     #   "agent_3_consolidation": {"final_amount": 1500.0, "conflicts_detected": 0, ...}
     # }
     ```

2. Create app/models/intent_classification.py:
   - Define EmailIntent enum with 6 values: debt_statement, payment_plan, rejection, inquiry, auto_reply, spam
   - Define IntentResult Pydantic model:
     ```python
     class IntentResult(BaseModel):
         intent: EmailIntent
         confidence: float  # 0.0-1.0
         method: str  # "header_auto_submitted", "subject_regex", "noreply_address", "claude_haiku"
         skip_extraction: bool = False  # True for auto_reply and spam
     ```

3. Update app/models/__init__.py to export IntentResult and EmailIntent

4. Create Alembic migration (use timestamp format like existing migrations):
   - Add agent_checkpoints JSONB column to incoming_emails table
   - Use nullable=True for backward compatibility
   - Add comment documenting the column purpose
  </action>
  <verify>
    - `python -c "from app.models.intent_classification import EmailIntent, IntentResult; print(EmailIntent.debt_statement)"`
    - `python -c "from app.models import IncomingEmail; print(hasattr(IncomingEmail, 'agent_checkpoints'))"`
    - `alembic check` shows no pending migrations (after creating migration)
  </verify>
  <done>
    - IncomingEmail has agent_checkpoints JSONB column
    - EmailIntent enum has 6 intent types
    - IntentResult model validates intent classification results
    - Alembic migration file created
  </done>
</task>

<task type="auto">
  <name>Task 2: Create validation services</name>
  <files>
    app/services/validation/__init__.py
    app/services/validation/schema_validator.py
    app/services/validation/confidence_checker.py
  </files>
  <action>
1. Create app/services/validation/ directory structure

2. Create app/services/validation/schema_validator.py:
   - Implement `validate_with_partial_results(data: dict, model_class: type) -> dict`:
     ```python
     def validate_with_partial_results(data: dict, model_class: type) -> dict:
         """
         Validate against Pydantic model, null failed fields, preserve good ones.
         USER DECISION: Proceed with partial results + needs_review flag.

         Returns:
             {
                 "data": {...},  # Validated or partial data
                 "needs_review": bool,
                 "validation_errors": [{"field": ..., "type": ..., "msg": ...}]
             }
         """
     ```
   - Use try/except ValidationError to catch errors
   - Extract failed field names from e.errors() using loc[0]
   - Null out failed fields, preserve valid fields
   - Set needs_review=True if any validation errors
   - Log with structlog

3. Create app/services/validation/confidence_checker.py:
   - Implement `check_confidence_threshold(confidence: float, threshold: float = 0.7) -> dict`:
     ```python
     def check_confidence_threshold(confidence: float, threshold: float = 0.7) -> dict:
         """
         Check if confidence meets threshold.
         USER DECISION: < 0.7 = needs_review flag, don't block pipeline.

         Returns:
             {"passes": bool, "needs_review": bool, "confidence": float, "threshold": float}
         """
     ```
   - Return needs_review=True if confidence < threshold (USER DECISION: 0.7)
   - Log confidence check results

4. Create app/services/validation/__init__.py:
   - Export validate_with_partial_results, check_confidence_threshold
  </action>
  <verify>
    - `python -c "from app.services.validation import validate_with_partial_results, check_confidence_threshold"`
    - `python -c "from app.services.validation.confidence_checker import check_confidence_threshold; print(check_confidence_threshold(0.5))"`
    - Expected: {"passes": False, "needs_review": True, "confidence": 0.5, "threshold": 0.7}
  </verify>
  <done>
    - validate_with_partial_results preserves partial data on validation failure
    - check_confidence_threshold flags items below 0.7 for review
    - Both functions are importable from app.services.validation
  </done>
</task>

<task type="auto">
  <name>Task 3: Add checkpoint save utility</name>
  <files>
    app/services/validation/checkpoint.py
    app/services/validation/__init__.py
  </files>
  <action>
1. Create app/services/validation/checkpoint.py:
   - Implement `save_checkpoint(db: Session, email_id: int, agent_name: str, result: dict) -> None`:
     ```python
     def save_checkpoint(db: Session, email_id: int, agent_name: str, result: dict) -> None:
         """
         Save agent result as checkpoint in IncomingEmail.agent_checkpoints JSONB.

         Agent names: "agent_1_intent", "agent_2_extraction", "agent_3_consolidation"

         Checkpoint includes timestamp and validation_status automatically.
         """
     ```
   - Load email by ID
   - Initialize agent_checkpoints as {} if None
   - Add timestamp (datetime.utcnow().isoformat()) to result
   - Store result under agent_name key
   - Commit to database
   - Log checkpoint save

   - Implement `get_checkpoint(db: Session, email_id: int, agent_name: str) -> Optional[dict]`:
     - Return cached checkpoint if exists (for replay/skip)
     - Return None if no checkpoint

   - Implement `has_valid_checkpoint(db: Session, email_id: int, agent_name: str) -> bool`:
     - Check if checkpoint exists with validation_status != "failed"
     - Used for skipping completed agents on retry

2. Update app/services/validation/__init__.py:
   - Add exports: save_checkpoint, get_checkpoint, has_valid_checkpoint
  </action>
  <verify>
    - `python -c "from app.services.validation import save_checkpoint, get_checkpoint, has_valid_checkpoint"`
    - Verify functions have correct signatures
  </verify>
  <done>
    - save_checkpoint persists agent results to JSONB column
    - get_checkpoint retrieves cached results for replay
    - has_valid_checkpoint enables skip-on-retry pattern
  </done>
</task>

</tasks>

<verification>
All foundation components for multi-agent pipeline:
1. `python -c "from app.models import IncomingEmail; print('agent_checkpoints' in [c.name for c in IncomingEmail.__table__.columns])"` returns True
2. `python -c "from app.models.intent_classification import EmailIntent; print(list(EmailIntent))"` shows 6 intent types
3. `python -c "from app.services.validation import validate_with_partial_results, check_confidence_threshold, save_checkpoint"`
4. `alembic heads` shows migration file exists
</verification>

<success_criteria>
- IncomingEmail.agent_checkpoints column defined and migration created
- EmailIntent enum with 6 intent types (debt_statement, payment_plan, rejection, inquiry, auto_reply, spam)
- IntentResult Pydantic model with intent, confidence, method, skip_extraction
- validate_with_partial_results preserves partial data on Pydantic validation failure
- check_confidence_threshold returns needs_review=True for confidence < 0.7
- Checkpoint utilities enable save/retrieve/check pattern
</success_criteria>

<output>
After completion, create `.planning/phases/05-multi-agent-pipeline-validation/05-01-SUMMARY.md`
</output>
